## ğŸ“Š Machine Learning and Computational Statistics Projects

This repository contains a comprehensive set of homework assignments and a final project for the course **Machine Learning and Computational Statistics**, focusing on theoretical foundations and hands-on implementation with Python, `scikit-learn`, and `matplotlib`.

---

### ğŸ“ HW2: Density Estimation

- Implemented parametric and non-parametric density estimation techniques.
- Compared histogram-based, kernel-based, and k-NN approaches on synthetic data.
- Evaluated accuracy through visualizations and error analysis.

---

### ğŸ“ HW3: Hypothesis Testing & Confidence Intervals

- Applied statistical hypothesis tests (Z-test, t-test, chi-square) to real data.
- Constructed confidence intervals for population mean and variance.
- Demonstrated error types and power of a test in practical settings.

---

### ğŸ“ HW4: Linear Regression

- Designed and trained univariate and multivariate linear regression models.
- Assessed model fit using MSE and RÂ² metrics.
- Visualized learned models on 2D and 3D plots.

---

### ğŸ“ HW5: Regularized Regression (Ridge & Lasso)

- Implemented Ridge and Lasso regression with closed-form and iterative methods.
- Performed model selection via cross-validation.
- Highlighted effects of regularization on parameter sparsity and performance.

---

### ğŸ“ HW6: Logistic Regression

- Developed logistic regression from scratch with gradient descent.
- Explored effects of the sigmoid scaling parameter `a`.
- Illustrated convergence behavior and classification boundaries.

---

### ğŸ“ HW7 & HW7a: Bayesian Classifiers

- Derived and applied Gaussian Naive Bayes and full-covariance Bayesian classifiers.
- Evaluated decision boundaries and confusion matrices.
- Compared with maximum likelihood classifiers.

---

### ğŸ“ HW8: Non-linear Logistic Regression

- Studied impact of varying sigmoid sharpness on model behavior.
- Derived gradient descent updates with analytical gradient of the cost.
- Discussed model calibration and limitations in class probabilities.

---

### ğŸ“ HW9a: Support Vector Machines

- Trained SVM classifiers using linear, polynomial, and RBF kernels.
- Tuned hyperparameters (`C`, `gamma`, `degree`) and evaluated classification performance.
- Visualized decision boundaries using 2D scatter plots and `matplotlib`.

---

### ğŸ›°ï¸ Final Project: Hyperspectral Image Classification

- **Objective:** Apply supervised classification and spectral unmixing on the Salinas HSI dataset.
- **Data:** Hyperspectral image cube of 220Ã—120Ã—204 resolution with labeled regions.
- **Tasks:**
  - Spectral unmixing using 5 methods (LS, constrained LS, LASSO)
  - Classification using SVM, k-NN, and random forest
  - Accuracy evaluation, confusion matrices, and visual inspection of unmixing maps
- **Tools:** `numpy`, `scipy`, `matplotlib`, `scikit-learn`, `spectral`, `cvxpy`

---